[
  {
    "title": "DeepSeek-OCR: Contexts Optical Compression",
    "authors": [
      "Haoran Wei",
      "Yaofeng Sun",
      "Yukun Li"
    ],
    "date": "2025-10-21T02:41:44Z",
    "url": "http://arxiv.org/abs/2510.18234v1",
    "source": "arxiv"
  },
  {
    "title": "Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?",
    "authors": [
      "Sri Durga Sai Sowmya Kadali",
      "Evangelos E. Papalexakis"
    ],
    "date": "2025-10-08T02:55:31Z",
    "url": "http://arxiv.org/abs/2510.06594v2",
    "source": "arxiv"
  },
  {
    "title": "Qwen3Guard Technical Report",
    "authors": [
      "Qwen Team"
    ],
    "date": "2025-09-23",
    "url": "https://github.com/QwenLM/Qwen3/blob/main/Qwen3_Technical_Report.pdf",
    "source": "manual"
  },
  {
    "title": "Defeating Nondeterminism in LLM Inference",
    "authors": [
      "Horace He",
      "Thinking Machines Lab"
    ],
    "date": "2025-09-10",
    "url": "https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/",
    "source": "manual"
  },
  {
    "title": "On the Theoretical Limitations of Embedding-Based Retrieval",
    "authors": [
      "Orion Weller",
      "Michael Boratko",
      "Iftekhar Naim",
      "Jinhyuk Lee"
    ],
    "date": "2025-08-28T17:43:53Z",
    "url": "http://arxiv.org/abs/2508.21038v1",
    "source": "arxiv"
  },
  {
    "title": "Safety Alignment Should Be Made More Than Just A Few Attention Heads",
    "authors": [
      "Chao Huang",
      "Zefeng Zhang",
      "Juewei Yue",
      "Quangang Li",
      "Chuang Zhang",
      "Tingwen Liu"
    ],
    "date": "2025-08-27T09:06:28Z",
    "url": "http://arxiv.org/abs/2508.19697v1",
    "source": "arxiv"
  },
  {
    "title": "Does More Inference-Time Compute Really Help Robustness?",
    "authors": [
      "Tong Wu",
      "Chong Xiang",
      "Jiachen T. Wang",
      "Weichen Yu",
      "Chawin Sitawarin",
      "Vikash Sehwag",
      "Prateek Mittal"
    ],
    "date": "2025-07-21T18:08:38Z",
    "url": "http://arxiv.org/abs/2507.15974v1",
    "source": "arxiv"
  },
  {
    "title": "Context Rot: How Increasing Input Tokens Impacts LLM Performance",
    "authors": [
      "Kelly Hong",
      "Anton Troynikov",
      "Jeff Huber"
    ],
    "date": "2025-07-14",
    "url": "https://research.trychroma.com/context-rot",
    "source": "manual"
  },
  {
    "title": "Adversarial Manipulation of Reasoning Models using Internal\n  Representations",
    "authors": [
      "Kureha Yamaguchi",
      "Benjamin Etheridge",
      "Andy Arditi"
    ],
    "date": "2025-07-03T20:51:32Z",
    "url": "http://arxiv.org/abs/2507.03167v2",
    "source": "arxiv"
  },
  {
    "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism\n  on Apple Silicon for Mixture-of-Experts Large Language Model",
    "authors": [
      "Mu-Chi Chen",
      "Po-Hsuan Huang",
      "Xiangrui Ke",
      "Chia-Heng Tu",
      "Chun Jason Xue",
      "Shih-Hao Hung"
    ],
    "date": "2025-06-30T09:04:25Z",
    "url": "http://arxiv.org/abs/2506.23635v1",
    "source": "arxiv"
  },
  {
    "title": "Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering\n  Target Atoms",
    "authors": [
      "Mengru Wang",
      "Ziwen Xu",
      "Shengyu Mao",
      "Shumin Deng",
      "Zhaopeng Tu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "date": "2025-05-23T17:59:18Z",
    "url": "http://arxiv.org/abs/2505.20322v2",
    "source": "arxiv"
  },
  {
    "title": "Context Reasoner: Incentivizing Reasoning Capability for Contextualized\n  Privacy and Safety Compliance via Reinforcement Learning",
    "authors": [
      "Wenbin Hu",
      "Haoran Li",
      "Huihao Jing",
      "Qi Hu",
      "Ziqian Zeng",
      "Sirui Han",
      "Heli Xu",
      "Tianshu Chu",
      "Peizhao Hu",
      "Yangqiu Song"
    ],
    "date": "2025-05-20T16:40:09Z",
    "url": "http://arxiv.org/abs/2505.14585v2",
    "source": "arxiv"
  },
  {
    "title": "ShieldGemma 2: Robust and Tractable Image Content Moderation",
    "authors": [
      "Wenjun Zeng",
      "Dana Kurniawan",
      "Ryan Mullins",
      "Yuchi Liu",
      "Tamoghna Saha",
      "Dirichi Ike-Njoku",
      "Jindong Gu",
      "Yiwen Song",
      "Cai Xu",
      "Jingjing Zhou",
      "Aparna Joshi",
      "Shravan Dheep",
      "Mani Malek",
      "Hamid Palangi",
      "Joon Baek",
      "Rick Pereira",
      "Karthik Narasimhan"
    ],
    "date": "2025-04-01T18:00:20Z",
    "url": "http://arxiv.org/abs/2504.01081v2",
    "source": "arxiv"
  },
  {
    "title": "Beyond Single-Sentence Prompts: Upgrading Value Alignment Benchmarks\n  with Dialogues and Stories",
    "authors": [
      "Yazhou Zhang",
      "Qimeng Liu",
      "Qiuchi Li",
      "Peng Zhang",
      "Jing Qin"
    ],
    "date": "2025-03-28T03:31:37Z",
    "url": "http://arxiv.org/abs/2503.22115v1",
    "source": "arxiv"
  },
  {
    "title": "Harnessing Chain-of-Thought Metadata for Task Routing and Adversarial\n  Prompt Detection",
    "authors": [
      "Ryan Marinelli",
      "Josef Pichlmeier",
      "Tamas Bisztray"
    ],
    "date": "2025-03-27T12:54:00Z",
    "url": "http://arxiv.org/abs/2503.21464v1",
    "source": "arxiv"
  },
  {
    "title": "Circuit Tracing: Revealing Computational Graphs in Language Models",
    "authors": [
      "Emmanuel Ameisen",
      "Jack Lindsey",
      "Adam Pearce",
      "Wes Gurnee",
      "Nicholas L. Turner",
      "Brian Chen",
      "Craig Citro",
      "David Abrahams",
      "Shan Carter",
      "Basil Hosmer",
      "Jonathan Marcus",
      "Michael Sklar",
      "Adly Templeton",
      "Trenton Bricken",
      "Callum McDougall",
      "Hoagy Cunningham",
      "Thomas Henighan",
      "Adam Jermyn",
      "Andy Jones",
      "Andrew Persic",
      "Zhenyi Qi",
      "T. Ben Thompson",
      "Sam Zimmerman",
      "Kelley Rivoire",
      "Thomas Conerly",
      "Chris Olah",
      "Joshua Batson"
    ],
    "date": "2025-03-27",
    "url": "https://transformer-circuits.pub/2025/attribution-graphs/methods.html#building-replacement",
    "source": "manual"
  },
  {
    "title": "On the Biology of a Large Language Model",
    "authors": [
      "Jack Lindsey",
      "Wes Gurnee",
      "Emmanuel Ameisen",
      "Brian Chen",
      "Adam Pearce",
      "Nicholas L. Turner",
      "Craig Citro",
      "David Abrahams",
      "Shan Carter",
      "Basil Hosmer",
      "Jonathan Marcus",
      "Michael Sklar",
      "Adly Templeton",
      "Trenton Bricken",
      "Callum McDougall",
      "Hoagy Cunningham",
      "Thomas Henighan",
      "Adam Jermyn",
      "Andy Jones",
      "Andrew Persic",
      "Zhenyi Qi",
      "T. Ben Thompson",
      "Sam Zimmerman",
      "Kelley Rivoire",
      "Thomas Conerly",
      "Chris Olah",
      "Joshua Batson"
    ],
    "date": "2025-03-27",
    "url": "https://transformer-circuits.pub/2025/attribution-graphs/biology.html",
    "source": "manual"
  },
  {
    "title": "Prompt Injection Detection and Mitigation via AI Multi-Agent NLP\n  Frameworks",
    "authors": [
      "Diego Gosmar",
      "Deborah A. Dahl",
      "Dario Gosmar"
    ],
    "date": "2025-03-14T15:41:45Z",
    "url": "http://arxiv.org/abs/2503.11517v1",
    "source": "arxiv"
  },
  {
    "title": "Beyond Surface-Level Patterns: An Essence-Driven Defense Framework\n  Against Jailbreak Attacks in LLMs",
    "authors": [
      "Shiyu Xiang",
      "Ansen Zhang",
      "Yanfei Cao",
      "Yang Fan",
      "Ronghao Chen"
    ],
    "date": "2025-02-26T10:53:58Z",
    "url": "http://arxiv.org/abs/2502.19041v2",
    "source": "arxiv"
  },
  {
    "title": "Do LLMs Understand the Safety of Their Inputs? Training-Free Moderation\n  via Latent Prototypes",
    "authors": [
      "Maciej Chrabąszcz",
      "Filip Szatkowski",
      "Bartosz Wójcik",
      "Jan Dubiński",
      "Tomasz Trzciński",
      "Sebastian Cygert"
    ],
    "date": "2025-02-22T10:31:50Z",
    "url": "http://arxiv.org/abs/2502.16174v2",
    "source": "arxiv"
  },
  {
    "title": "Attention Eclipse: Manipulating Attention to Bypass LLM Safety-Alignment",
    "authors": [
      "Pedram Zaree",
      "Md Abdullah Al Mamun",
      "Quazi Mishkatul Alam",
      "Yue Dong",
      "Ihsen Alouani",
      "Nael Abu-Ghazaleh"
    ],
    "date": "2025-02-21T09:38:00Z",
    "url": "http://arxiv.org/abs/2502.15334v1",
    "source": "arxiv"
  },
  {
    "title": "AILuminate: Introducing v1.0 of the AI Risk and Reliability Benchmark\n  from MLCommons",
    "authors": [
      "Shaona Ghosh",
      "Heather Frase",
      "Adina Williams",
      "Sarah Luger",
      "Paul Röttger",
      "Fazl Barez",
      "Sean McGregor",
      "Kenneth Fricklas",
      "Mala Kumar",
      "Quentin Feuillade--Montixi",
      "Kurt Bollacker",
      "Felix Friedrich",
      "Ryan Tsang",
      "Bertie Vidgen",
      "Alicia Parrish",
      "Chris Knotz",
      "Eleonora Presani",
      "Jonathan Bennion",
      "Marisa Ferrara Boston",
      "Mike Kuniavsky",
      "Wiebke Hutiri",
      "James Ezick",
      "Malek Ben Salem",
      "Rajat Sahay",
      "Sujata Goswami",
      "Usman Gohar",
      "Ben Huang",
      "Supheakmungkol Sarin",
      "Elie Alhajjar",
      "Canyu Chen",
      "Roman Eng",
      "Kashyap Ramanandula Manjusha",
      "Virendra Mehta",
      "Eileen Long",
      "Murali Emani",
      "Natan Vidra",
      "Benjamin Rukundo",
      "Abolfazl Shahbazi",
      "Kongtao Chen",
      "Rajat Ghosh",
      "Vithursan Thangarasa",
      "Pierre Peigné",
      "Abhinav Singh",
      "Max Bartolo",
      "Satyapriya Krishna",
      "Mubashara Akhtar",
      "Rafael Gold",
      "Cody Coleman",
      "Luis Oala",
      "Vassil Tashev",
      "Joseph Marvin Imperial",
      "Amy Russ",
      "Sasidhar Kunapuli",
      "Nicolas Miailhe",
      "Julien Delaunay",
      "Bhaktipriya Radharapu",
      "Rajat Shinde",
      "Tuesday",
      "Debojyoti Dutta",
      "Declan Grabb",
      "Ananya Gangavarapu",
      "Saurav Sahay",
      "Agasthya Gangavarapu",
      "Patrick Schramowski",
      "Stephen Singam",
      "Tom David",
      "Xudong Han",
      "Priyanka Mary Mammen",
      "Tarunima Prabhakar",
      "Venelin Kovatchev",
      "Rebecca Weiss",
      "Ahmed Ahmed",
      "Kelvin N. Manyeki",
      "Sandeep Madireddy",
      "Foutse Khomh",
      "Fedor Zhdanov",
      "Joachim Baumann",
      "Nina Vasan",
      "Xianjun Yang",
      "Carlos Mougn",
      "Jibin Rajan Varghese",
      "Hussain Chinoy",
      "Seshakrishna Jitendar",
      "Manil Maskey",
      "Claire V. Hardgrove",
      "Tianhao Li",
      "Aakash Gupta",
      "Emil Joswin",
      "Yifan Mai",
      "Shachi H Kumar",
      "Cigdem Patlak",
      "Kevin Lu",
      "Vincent Alessi",
      "Sree Bhargavi Balija",
      "Chenhe Gu",
      "Robert Sullivan",
      "James Gealy",
      "Matt Lavrisa",
      "James Goel",
      "Peter Mattson",
      "Percy Liang",
      "Joaquin Vanschoren"
    ],
    "date": "2025-02-19T05:58:52Z",
    "url": "http://arxiv.org/abs/2503.05731v2",
    "source": "arxiv"
  },
  {
    "title": "Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language\n  Model Guardrails",
    "authors": [
      "Yijun Yang",
      "Lichao Wang",
      "Xiao Yang",
      "Lanqing Hong",
      "Jun Zhu"
    ],
    "date": "2025-02-09T04:21:27Z",
    "url": "http://arxiv.org/abs/2502.05772v1",
    "source": "arxiv"
  },
  {
    "title": "SafeSwitch: Steering Unsafe LLM Behavior via Internal Activation Signals",
    "authors": [
      "Peixuan Han",
      "Cheng Qian",
      "Xiusi Chen",
      "Yuji Zhang",
      "Heng Ji",
      "Denghui Zhang"
    ],
    "date": "2025-02-03T04:23:33Z",
    "url": "http://arxiv.org/abs/2502.01042v5",
    "source": "arxiv"
  },
  {
    "title": "SafeSwitch: Steering Unsafe LLM Behavior via Internal Activation Signals",
    "authors": [
      "Peixuan Han",
      "Cheng Qian",
      "Xiusi Chen",
      "Yuji Zhang",
      "Heng Ji",
      "Denghui Zhang"
    ],
    "date": "2025-02-03T04:23:33Z",
    "url": "http://arxiv.org/abs/2502.01042v5",
    "source": "arxiv"
  },
  {
    "title": "PromptShield: Deployable Detection for Prompt Injection Attacks",
    "authors": [
      "Dennis Jacob",
      "Hend Alzahrani",
      "Zhanhao Hu",
      "Basel Alomair",
      "David Wagner"
    ],
    "date": "2025-01-25T09:03:19Z",
    "url": "http://arxiv.org/abs/2501.15145v2",
    "source": "arxiv"
  },
  {
    "title": "Enhancing Semantic Consistency of Large Language Models through Model\n  Editing: An Interpretability-Oriented Approach",
    "authors": [
      "Jingyuan Yang",
      "Dapeng Chen",
      "Yajing Sun",
      "Rongjun Li",
      "Zhiyong Feng",
      "Wei Peng"
    ],
    "date": "2025-01-19T13:26:15Z",
    "url": "http://arxiv.org/abs/2501.11041v1",
    "source": "arxiv"
  },
  {
    "title": "Spot Risks Before Speaking! Unraveling Safety Attention Heads in Large\n  Vision-Language Models",
    "authors": [
      "Ziwei Zheng",
      "Junyao Zhao",
      "Le Yang",
      "Lijun He",
      "Fan Li"
    ],
    "date": "2025-01-03T07:01:15Z",
    "url": "http://arxiv.org/abs/2501.02029v1",
    "source": "arxiv"
  },
  {
    "title": "Deliberative Alignment: Reasoning Enables Safer Language Models",
    "authors": [
      "Melody Y. Guan",
      "Manas Joglekar",
      "Eric Wallace",
      "Saachi Jain",
      "Boaz Barak",
      "Alec Helyar",
      "Rachel Dias",
      "Andrea Vallone",
      "Hongyu Ren",
      "Jason Wei",
      "Hyung Won Chung",
      "Sam Toyer",
      "Johannes Heidecke",
      "Alex Beutel",
      "Amelia Glaese"
    ],
    "date": "2024-12-20T21:00:11Z",
    "url": "http://arxiv.org/abs/2412.16339v2",
    "source": "arxiv"
  },
  {
    "title": "LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety\n  Inconsistencies",
    "authors": [
      "Felix Friedrich",
      "Simone Tedeschi",
      "Patrick Schramowski",
      "Manuel Brack",
      "Roberto Navigli",
      "Huu Nguyen",
      "Bo Li",
      "Kristian Kersting"
    ],
    "date": "2024-12-19T16:46:54Z",
    "url": "http://arxiv.org/abs/2412.15035v3",
    "source": "arxiv"
  },
  {
    "title": "Lightweight Safety Classification Using Pruned Language Models",
    "authors": [
      "Mason Sawtell",
      "Tula Masterman",
      "Sandi Besen",
      "Jim Brown"
    ],
    "date": "2024-12-18T02:13:13Z",
    "url": "http://arxiv.org/abs/2412.13435v1",
    "source": "arxiv"
  },
  {
    "title": "LLMs are Also Effective Embedding Models: An In-depth Overview",
    "authors": [
      "Chongyang Tao",
      "Tao Shen",
      "Shen Gao",
      "Junshuo Zhang",
      "Zhen Li",
      "Kai Hua",
      "Wenpeng Hu",
      "Zhengwei Tao",
      "Shuai Ma"
    ],
    "date": "2024-12-17T06:48:24Z",
    "url": "http://arxiv.org/abs/2412.12591v2",
    "source": "arxiv"
  },
  {
    "title": "All Languages Matter: Evaluating LMMs on Culturally Diverse 100\n  Languages",
    "authors": [
      "Ashmal Vayani",
      "Dinura Dissanayake",
      "Hasindri Watawana",
      "Noor Ahsan",
      "Nevasini Sasikumar",
      "Omkar Thawakar",
      "Henok Biadglign Ademtew",
      "Yahya Hmaiti",
      "Amandeep Kumar",
      "Kartik Kuckreja",
      "Mykola Maslych",
      "Wafa Al Ghallabi",
      "Mihail Mihaylov",
      "Chao Qin",
      "Abdelrahman M Shaker",
      "Mike Zhang",
      "Mahardika Krisna Ihsani",
      "Amiel Esplana",
      "Monil Gokani",
      "Shachar Mirkin",
      "Harsh Singh",
      "Ashay Srivastava",
      "Endre Hamerlik",
      "Fathinah Asma Izzati",
      "Fadillah Adamsyah Maani",
      "Sebastian Cavada",
      "Jenny Chim",
      "Rohit Gupta",
      "Sanjay Manjunath",
      "Kamila Zhumakhanova",
      "Feno Heriniaina Rabevohitra",
      "Azril Amirudin",
      "Muhammad Ridzuan",
      "Daniya Kareem",
      "Ketan More",
      "Kunyang Li",
      "Pramesh Shakya",
      "Muhammad Saad",
      "Amirpouya Ghasemaghaei",
      "Amirbek Djanibekov",
      "Dilshod Azizov",
      "Branislava Jankovic",
      "Naman Bhatia",
      "Alvaro Cabrera",
      "Johan Obando-Ceron",
      "Olympiah Otieno",
      "Fabian Farestam",
      "Muztoba Rabbani",
      "Sanoojan Baliah",
      "Santosh Sanjeev",
      "Abduragim Shtanchaev",
      "Maheen Fatima",
      "Thao Nguyen",
      "Amrin Kareem",
      "Toluwani Aremu",
      "Nathan Xavier",
      "Amit Bhatkal",
      "Hawau Toyin",
      "Aman Chadha",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer",
      "Michael Felsberg",
      "Jorma Laaksonen",
      "Thamar Solorio",
      "Monojit Choudhury",
      "Ivan Laptev",
      "Mubarak Shah",
      "Salman Khan",
      "Fahad Khan"
    ],
    "date": "2024-11-25T15:44:42Z",
    "url": "http://arxiv.org/abs/2411.16508v4",
    "source": "arxiv"
  },
  {
    "title": "Llama Guard 3-1B-INT4: Compact and Efficient Safeguard for Human-AI\n  Conversations",
    "authors": [
      "Igor Fedorov",
      "Kate Plawiak",
      "Lemeng Wu",
      "Tarek Elgamal",
      "Naveen Suda",
      "Eric Smith",
      "Hongyuan Zhan",
      "Jianfeng Chi",
      "Yuriy Hulovatyy",
      "Kimish Patel",
      "Zechun Liu",
      "Changsheng Zhao",
      "Yangyang Shi",
      "Tijmen Blankevoort",
      "Mahesh Pasupuleti",
      "Bilge Soran",
      "Zacharie Delpierre Coudert",
      "Rachad Alao",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra"
    ],
    "date": "2024-11-18T21:42:17Z",
    "url": "http://arxiv.org/abs/2411.17713v1",
    "source": "arxiv"
  },
  {
    "title": "When are 1.58 bits enough? A Bottom-up Exploration of BitNet\n  Quantization",
    "authors": [
      "Jacob Nielsen",
      "Lukas Galke",
      "Peter Schneider-Kamp"
    ],
    "date": "2024-11-08T07:24:49Z",
    "url": "http://arxiv.org/abs/2411.05882v1",
    "source": "arxiv"
  },
  {
    "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
    "authors": [
      "Kuo-Han Hung",
      "Ching-Yun Ko",
      "Ambrish Rawat",
      "I-Hsin Chung",
      "Winston H. Hsu",
      "Pin-Yu Chen"
    ],
    "date": "2024-11-01T04:05:59Z",
    "url": "http://arxiv.org/abs/2411.00348v2",
    "source": "arxiv"
  },
  {
    "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs",
    "authors": [
      "Kuo-Han Hung",
      "Ching-Yun Ko",
      "Ambrish Rawat",
      "I-Hsin Chung",
      "Winston H. Hsu",
      "Pin-Yu Chen"
    ],
    "date": "2024-11-01T04:05:59Z",
    "url": "http://arxiv.org/abs/2411.00348v2",
    "source": "arxiv"
  },
  {
    "title": "Embedding-based classifiers can detect prompt injection attacks",
    "authors": [
      "Md. Ahsan Ayub",
      "Subhabrata Majumdar"
    ],
    "date": "2024-10-29T17:36:59Z",
    "url": "http://arxiv.org/abs/2410.22284v1",
    "source": "arxiv"
  },
  {
    "title": "AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to\n  Jailbreak LLMs with Higher Success Rates in Fewer Attempts",
    "authors": [
      "Vishal Kumar",
      "Zeyi Liao",
      "Jaylen Jones",
      "Huan Sun"
    ],
    "date": "2024-10-29T15:40:07Z",
    "url": "http://arxiv.org/abs/2410.22143v1",
    "source": "arxiv"
  },
  {
    "title": "Palisade -- Prompt Injection Detection Framework",
    "authors": [
      "Sahasra Kokkula",
      "Somanathan R",
      "Nandavardhan R",
      "Aashishkumar",
      "G Divya"
    ],
    "date": "2024-10-28T15:47:03Z",
    "url": "http://arxiv.org/abs/2410.21146v1",
    "source": "arxiv"
  },
  {
    "title": "Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities",
    "authors": [
      "Chung-En Sun",
      "Xiaodong Liu",
      "Weiwei Yang",
      "Tsui-Wei Weng",
      "Hao Cheng",
      "Aidan San",
      "Michel Galley",
      "Jianfeng Gao"
    ],
    "date": "2024-10-24T06:36:12Z",
    "url": "http://arxiv.org/abs/2410.18469v5",
    "source": "arxiv"
  },
  {
    "title": "An Interpretable N-gram Perplexity Threat Model for Large Language Model\n  Jailbreaks",
    "authors": [
      "Valentyn Boreiko",
      "Alexander Panfilov",
      "Vaclav Voracek",
      "Matthias Hein",
      "Jonas Geiping"
    ],
    "date": "2024-10-21T17:27:01Z",
    "url": "http://arxiv.org/abs/2410.16222v2",
    "source": "arxiv"
  },
  {
    "title": "Boosting Jailbreak Transferability for Large Language Models",
    "authors": [
      "Hanqing Liu",
      "Lifeng Zhou",
      "Huanqian Yan"
    ],
    "date": "2024-10-21T05:11:19Z",
    "url": "http://arxiv.org/abs/2410.15645v2",
    "source": "arxiv"
  },
  {
    "title": "Feint and Attack: Attention-Based Strategies for Jailbreaking and\n  Protecting LLMs",
    "authors": [
      "Rui Pu",
      "Chaozhuo Li",
      "Rui Ha",
      "Zejian Chen",
      "Litian Zhang",
      "Zheng Liu",
      "Lirong Qiu",
      "Zaisheng Ye"
    ],
    "date": "2024-10-18T17:02:13Z",
    "url": "http://arxiv.org/abs/2410.16327v2",
    "source": "arxiv"
  },
  {
    "title": "On the Role of Attention Heads in Large Language Model Safety",
    "authors": [
      "Zhenhong Zhou",
      "Haiyang Yu",
      "Xinghua Zhang",
      "Rongwu Xu",
      "Fei Huang",
      "Kun Wang",
      "Yang Liu",
      "Junfeng Fang",
      "Yongbin Li"
    ],
    "date": "2024-10-17T16:08:06Z",
    "url": "http://arxiv.org/abs/2410.13708v2",
    "source": "arxiv"
  },
  {
    "title": "Locking Down the Finetuned LLMs Safety",
    "authors": [
      "Minjun Zhu",
      "Linyi Yang",
      "Yifan Wei",
      "Ningyu Zhang",
      "Yue Zhang"
    ],
    "date": "2024-10-14T09:58:29Z",
    "url": "http://arxiv.org/abs/2410.10343v1",
    "source": "arxiv"
  },
  {
    "title": "Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting",
    "authors": [
      "Yifan Luo",
      "Zhennan Zhou",
      "Meitan Wang",
      "Bin Dong"
    ],
    "date": "2024-10-14T04:32:22Z",
    "url": "http://arxiv.org/abs/2410.10150v1",
    "source": "arxiv"
  },
  {
    "title": "AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention\n  Manipulation",
    "authors": [
      "Zijun Wang",
      "Haoqin Tu",
      "Jieru Mei",
      "Bingchen Zhao",
      "Yisen Wang",
      "Cihang Xie"
    ],
    "date": "2024-10-11T17:55:09Z",
    "url": "http://arxiv.org/abs/2410.09040v1",
    "source": "arxiv"
  },
  {
    "title": "Applying Pre-trained Multilingual BERT in Embeddings for Improved\n  Malicious Prompt Injection Attacks Detection",
    "authors": [
      "Md Abdur Rahman",
      "Hossain Shahriar",
      "Fan Wu",
      "Alfredo Cuzzocrea"
    ],
    "date": "2024-09-20T08:48:51Z",
    "url": "http://arxiv.org/abs/2409.13331v1",
    "source": "arxiv"
  },
  {
    "title": "Attention Heads of Large Language Models: A Survey",
    "authors": [
      "Zifan Zheng",
      "Yezhaohui Wang",
      "Yuxin Huang",
      "Shichao Song",
      "Mingchuan Yang",
      "Bo Tang",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "date": "2024-09-05T17:59:12Z",
    "url": "http://arxiv.org/abs/2409.03752v3",
    "source": "arxiv"
  },
  {
    "title": "ShieldGemma: Generative AI Content Moderation Based on Gemma",
    "authors": [
      "Wenjun Zeng",
      "Yuchi Liu",
      "Ryan Mullins",
      "Ludovic Peran",
      "Joe Fernandez",
      "Hamza Harkous",
      "Karthik Narasimhan",
      "Drew Proud",
      "Piyush Kumar",
      "Bhaktipriya Radharapu",
      "Olivia Sturman",
      "Oscar Wahltinez"
    ],
    "date": "2024-07-31T17:48:14Z",
    "url": "http://arxiv.org/abs/2407.21772v2",
    "source": "arxiv"
  },
  {
    "title": "ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large\n  Language Models",
    "authors": [
      "Mingrui Wu",
      "Xinyue Cai",
      "Jiayi Ji",
      "Jiale Li",
      "Oucheng Huang",
      "Gen Luo",
      "Hao Fei",
      "Guannan Jiang",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "date": "2024-07-31T11:40:29Z",
    "url": "http://arxiv.org/abs/2407.21534v6",
    "source": "arxiv"
  },
  {
    "title": "Detecting and Understanding Vulnerabilities in Language Models via\n  Mechanistic Interpretability",
    "authors": [
      "Jorge García-Carrasco",
      "Alejandro Maté",
      "Juan Trujillo"
    ],
    "date": "2024-07-29T09:55:34Z",
    "url": "http://arxiv.org/abs/2407.19842v1",
    "source": "arxiv"
  },
  {
    "title": "What Makes and Breaks Safety Fine-tuning? A Mechanistic Study",
    "authors": [
      "Samyak Jain",
      "Ekdeep Singh Lubana",
      "Kemal Oksuz",
      "Tom Joy",
      "Philip H. S. Torr",
      "Amartya Sanyal",
      "Puneet K. Dokania"
    ],
    "date": "2024-07-14T16:12:57Z",
    "url": "http://arxiv.org/abs/2407.10264v3",
    "source": "arxiv"
  },
  {
    "title": "Multilingual Blending: LLM Safety Alignment Evaluation with Language\n  Mixture",
    "authors": [
      "Jiayang Song",
      "Yuheng Huang",
      "Zhehua Zhou",
      "Lei Ma"
    ],
    "date": "2024-07-10T03:26:15Z",
    "url": "http://arxiv.org/abs/2407.07342v1",
    "source": "arxiv"
  },
  {
    "title": "Grounding and Evaluation for Large Language Models: Practical Challenges\n  and Lessons Learned (Survey)",
    "authors": [
      "Krishnaram Kenthapadi",
      "Mehrnoosh Sameki",
      "Ankur Taly"
    ],
    "date": "2024-07-10T01:23:10Z",
    "url": "http://arxiv.org/abs/2407.12858v1",
    "source": "arxiv"
  },
  {
    "title": "Jailbreak Attacks and Defenses Against Large Language Models: A Survey",
    "authors": [
      "Sibo Yi",
      "Yule Liu",
      "Zhen Sun",
      "Tianshuo Cong",
      "Xinlei He",
      "Jiaxing Song",
      "Ke Xu",
      "Qi Li"
    ],
    "date": "2024-07-05T06:57:30Z",
    "url": "http://arxiv.org/abs/2407.04295v2",
    "source": "arxiv"
  },
  {
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "authors": [
      "Ziqing Yang",
      "Michael Backes",
      "Yang Zhang",
      "Ahmed Salem"
    ],
    "date": "2024-07-03T14:35:16Z",
    "url": "http://arxiv.org/abs/2407.03160v1",
    "source": "arxiv"
  },
  {
    "title": "WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially)\n  Safer Language Models",
    "authors": [
      "Liwei Jiang",
      "Kavel Rao",
      "Seungju Han",
      "Allyson Ettinger",
      "Faeze Brahman",
      "Sachin Kumar",
      "Niloofar Mireshghallah",
      "Ximing Lu",
      "Maarten Sap",
      "Yejin Choi",
      "Nouha Dziri"
    ],
    "date": "2024-06-26T17:31:22Z",
    "url": "http://arxiv.org/abs/2406.18510v1",
    "source": "arxiv"
  },
  {
    "title": "On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language\n  Models",
    "authors": [
      "Sree Harsha Tanneru",
      "Dan Ley",
      "Chirag Agarwal",
      "Himabindu Lakkaraju"
    ],
    "date": "2024-06-15T13:16:44Z",
    "url": "http://arxiv.org/abs/2406.10625v2",
    "source": "arxiv"
  },
  {
    "title": "CHiSafetyBench: A Chinese Hierarchical Safety Benchmark for Large\n  Language Models",
    "authors": [
      "Wenjing Zhang",
      "Xuejiao Lei",
      "Zhaoxiang Liu",
      "Meijuan An",
      "Bikun Yang",
      "KaiKai Zhao",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "date": "2024-06-14T06:47:40Z",
    "url": "http://arxiv.org/abs/2406.10311v2",
    "source": "arxiv"
  },
  {
    "title": "Improving Language Models for Emotion Analysis: Insights from Cognitive\n  Science",
    "authors": [
      "Constant Bonard",
      "Gustave Cortal"
    ],
    "date": "2024-06-11T07:42:13Z",
    "url": "http://arxiv.org/abs/2406.10265v2",
    "source": "arxiv"
  },
  {
    "title": "Safety Alignment Should Be Made More Than Just a Few Tokens Deep",
    "authors": [
      "Xiangyu Qi",
      "Ashwinee Panda",
      "Kaifeng Lyu",
      "Xiao Ma",
      "Subhrajit Roy",
      "Ahmad Beirami",
      "Prateek Mittal",
      "Peter Henderson"
    ],
    "date": "2024-06-10T00:35:23Z",
    "url": "http://arxiv.org/abs/2406.05946v1",
    "source": "arxiv"
  },
  {
    "title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models\n  and Their Defenses",
    "authors": [
      "Xiaosen Zheng",
      "Tianyu Pang",
      "Chao Du",
      "Qian Liu",
      "Jing Jiang",
      "Min Lin"
    ],
    "date": "2024-06-03T12:59:17Z",
    "url": "http://arxiv.org/abs/2406.01288v2",
    "source": "arxiv"
  },
  {
    "title": "Improved Techniques for Optimization-Based Jailbreaking on Large\n  Language Models",
    "authors": [
      "Xiaojun Jia",
      "Tianyu Pang",
      "Chao Du",
      "Yihao Huang",
      "Jindong Gu",
      "Yang Liu",
      "Xiaochun Cao",
      "Min Lin"
    ],
    "date": "2024-05-31T17:07:15Z",
    "url": "http://arxiv.org/abs/2405.21018v2",
    "source": "arxiv"
  },
  {
    "title": "SLM as Guardian: Pioneering AI Safety with Small Language Models",
    "authors": [
      "Ohjoon Kwon",
      "Donghyeon Jeon",
      "Nayoung Choi",
      "Gyu-Hwung Cho",
      "Changbong Kim",
      "Hyunwoo Lee",
      "Inho Kang",
      "Sun Kim",
      "Taiwoo Park"
    ],
    "date": "2024-05-30T08:03:15Z",
    "url": "http://arxiv.org/abs/2405.19795v1",
    "source": "arxiv"
  },
  {
    "title": "Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning\n  Large Language Models",
    "authors": [
      "Chia-Yi Hsu",
      "Yu-Lin Tsai",
      "Chih-Hsun Lin",
      "Pin-Yu Chen",
      "Chia-Mu Yu",
      "Chun-Ying Huang"
    ],
    "date": "2024-05-27T05:04:05Z",
    "url": "http://arxiv.org/abs/2405.16833v2",
    "source": "arxiv"
  },
  {
    "title": "Large Language Model Sentinel: LLM Agent for Adversarial Purification",
    "authors": [
      "Guang Lin",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ],
    "date": "2024-05-24T07:23:56Z",
    "url": "http://arxiv.org/abs/2405.20770v4",
    "source": "arxiv"
  },
  {
    "title": "Efficient Universal Goal Hijacking with Semantics-guided Prompt\n  Organization",
    "authors": [
      "Yihao Huang",
      "Chong Wang",
      "Xiaojun Jia",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Jian Zhang",
      "Geguang Pu",
      "Yang Liu"
    ],
    "date": "2024-05-23T05:31:41Z",
    "url": "http://arxiv.org/abs/2405.14189v2",
    "source": "arxiv"
  },
  {
    "title": "Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained\n  Optimization",
    "authors": [
      "Kai Hu",
      "Weichen Yu",
      "Yining Li",
      "Kai Chen",
      "Tianjun Yao",
      "Xiang Li",
      "Wenhe Liu",
      "Lijun Yu",
      "Zhiqiang Shen",
      "Matt Fredrikson"
    ],
    "date": "2024-05-15T06:11:24Z",
    "url": "http://arxiv.org/abs/2405.09113v2",
    "source": "arxiv"
  },
  {
    "title": "Boosting Jailbreak Attack with Momentum",
    "authors": [
      "Yihao Zhang",
      "Zeming Wei"
    ],
    "date": "2024-05-02T12:18:14Z",
    "url": "http://arxiv.org/abs/2405.01229v2",
    "source": "arxiv"
  },
  {
    "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural\n  Language Processing",
    "authors": [
      "Yucheng Hu",
      "Yuxing Lu"
    ],
    "date": "2024-04-30T13:14:51Z",
    "url": "http://arxiv.org/abs/2404.19543v2",
    "source": "arxiv"
  },
  {
    "title": "RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?",
    "authors": [
      "Adrian de Wynter",
      "Ishaan Watts",
      "Tua Wongsangaroonsri",
      "Minghui Zhang",
      "Noura Farra",
      "Nektar Ege Altıntoprak",
      "Lena Baur",
      "Samantha Claudet",
      "Pavel Gajdusek",
      "Can Gören",
      "Qilong Gu",
      "Anna Kaminska",
      "Tomasz Kaminski",
      "Ruby Kuo",
      "Akiko Kyuba",
      "Jongho Lee",
      "Kartik Mathur",
      "Petter Merok",
      "Ivana Milovanović",
      "Nani Paananen",
      "Vesa-Matti Paananen",
      "Anna Pavlenko",
      "Bruno Pereira Vidal",
      "Luciano Strika",
      "Yueh Tsao",
      "Davide Turcato",
      "Oleksandr Vakhno",
      "Judit Velcsov",
      "Anna Vickers",
      "Stéphanie Visser",
      "Herdyan Widarmanto",
      "Andrey Zaikin",
      "Si-Qing Chen"
    ],
    "date": "2024-04-22T17:56:26Z",
    "url": "http://arxiv.org/abs/2404.14397v2",
    "source": "arxiv"
  },
  {
    "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs",
    "authors": [
      "Anselm Paulus",
      "Arman Zharmagambetov",
      "Chuan Guo",
      "Brandon Amos",
      "Yuandong Tian"
    ],
    "date": "2024-04-21T22:18:13Z",
    "url": "http://arxiv.org/abs/2404.16873v2",
    "source": "arxiv"
  },
  {
    "title": "AmpleGCG: Learning a Universal and Transferable Generative Model of\n  Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs",
    "authors": [
      "Zeyi Liao",
      "Huan Sun"
    ],
    "date": "2024-04-11T17:05:50Z",
    "url": "http://arxiv.org/abs/2404.07921v3",
    "source": "arxiv"
  },
  {
    "title": "Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs",
    "authors": [
      "Bibek Upadhayay",
      "Vahid Behzadan"
    ],
    "date": "2024-04-09T18:29:42Z",
    "url": "http://arxiv.org/abs/2404.07242v1",
    "source": "arxiv"
  },
  {
    "title": "AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM\n  Experts",
    "authors": [
      "Shaona Ghosh",
      "Prasoon Varshney",
      "Erick Galinkin",
      "Christopher Parisien"
    ],
    "date": "2024-04-09T03:54:28Z",
    "url": "http://arxiv.org/abs/2404.05993v2",
    "source": "arxiv"
  },
  {
    "title": "Non-Linear Inference Time Intervention: Improving LLM Truthfulness",
    "authors": [
      "Jakub Hoscilowicz",
      "Adam Wiacek",
      "Jan Chojnacki",
      "Adam Cieslak",
      "Leszek Michon",
      "Vitalii Urbanevych",
      "Artur Janicki"
    ],
    "date": "2024-03-27T15:22:16Z",
    "url": "http://arxiv.org/abs/2403.18680v2",
    "source": "arxiv"
  },
  {
    "title": "Defending Against Indirect Prompt Injection Attacks With Spotlighting",
    "authors": [
      "Keegan Hines",
      "Gary Lopez",
      "Matthew Hall",
      "Federico Zarfati",
      "Yonatan Zunger",
      "Emre Kiciman"
    ],
    "date": "2024-03-20T15:26:23Z",
    "url": "http://arxiv.org/abs/2403.14720v1",
    "source": "arxiv"
  },
  {
    "title": "RigorLLM: Resilient Guardrails for Large Language Models against\n  Undesired Content",
    "authors": [
      "Zhuowen Yuan",
      "Zidi Xiong",
      "Yi Zeng",
      "Ning Yu",
      "Ruoxi Jia",
      "Dawn Song",
      "Bo Li"
    ],
    "date": "2024-03-19T07:25:02Z",
    "url": "http://arxiv.org/abs/2403.13031v2",
    "source": "arxiv"
  },
  {
    "title": "Distract Large Language Models for Automatic Jailbreak Attack",
    "authors": [
      "Zeguan Xiao",
      "Yan Yang",
      "Guanhua Chen",
      "Yun Chen"
    ],
    "date": "2024-03-13T11:16:43Z",
    "url": "http://arxiv.org/abs/2403.08424v2",
    "source": "arxiv"
  },
  {
    "title": "From One to Many: Expanding the Scope of Toxicity Mitigation in Language\n  Models",
    "authors": [
      "Luiza Pozzobon",
      "Patrick Lewis",
      "Sara Hooker",
      "Beyza Ermis"
    ],
    "date": "2024-03-06T17:51:43Z",
    "url": "http://arxiv.org/abs/2403.03893v3",
    "source": "arxiv"
  },
  {
    "title": "Breaking Down the Defenses: A Comparative Survey of Attacks on Large\n  Language Models",
    "authors": [
      "Arijit Ghosh Chowdhury",
      "Md Mofijul Islam",
      "Vaibhav Kumar",
      "Faysal Hossain Shezan",
      "Vaibhav Kumar",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "date": "2024-03-03T04:46:21Z",
    "url": "http://arxiv.org/abs/2403.04786v2",
    "source": "arxiv"
  },
  {
    "title": "Breaking Down the Defenses: A Comparative Survey of Attacks on Large\n  Language Models",
    "authors": [
      "Arijit Ghosh Chowdhury",
      "Md Mofijul Islam",
      "Vaibhav Kumar",
      "Faysal Hossain Shezan",
      "Vaibhav Kumar",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "date": "2024-03-03T04:46:21Z",
    "url": "http://arxiv.org/abs/2403.04786v2",
    "source": "arxiv"
  },
  {
    "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks",
    "authors": [
      "Yifan Zeng",
      "Yiran Wu",
      "Xiao Zhang",
      "Huazheng Wang",
      "Qingyun Wu"
    ],
    "date": "2024-03-02T16:52:22Z",
    "url": "http://arxiv.org/abs/2403.04783v2",
    "source": "arxiv"
  },
  {
    "title": "Making Them Ask and Answer: Jailbreaking Large Language Models in Few\n  Queries via Disguise and Reconstruction",
    "authors": [
      "Tong Liu",
      "Yingjie Zhang",
      "Zhe Zhao",
      "Yinpeng Dong",
      "Guozhu Meng",
      "Kai Chen"
    ],
    "date": "2024-02-28T06:50:14Z",
    "url": "http://arxiv.org/abs/2402.18104v2",
    "source": "arxiv"
  },
  {
    "title": "Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts",
    "authors": [
      "Mikayel Samvelyan",
      "Sharath Chandra Raparthy",
      "Andrei Lupu",
      "Eric Hambro",
      "Aram H. Markosyan",
      "Manish Bhatt",
      "Yuning Mao",
      "Minqi Jiang",
      "Jack Parker-Holder",
      "Jakob Foerster",
      "Tim Rocktäschel",
      "Roberta Raileanu"
    ],
    "date": "2024-02-26T18:47:27Z",
    "url": "http://arxiv.org/abs/2402.16822v3",
    "source": "arxiv"
  },
  {
    "title": "CodeChameleon: Personalized Encryption Framework for Jailbreaking Large\n  Language Models",
    "authors": [
      "Huijie Lv",
      "Xiao Wang",
      "Yuansen Zhang",
      "Caishuang Huang",
      "Shihan Dou",
      "Junjie Ye",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "date": "2024-02-26T16:35:59Z",
    "url": "http://arxiv.org/abs/2402.16717v1",
    "source": "arxiv"
  },
  {
    "title": "Defending Large Language Models against Jailbreak Attacks via Semantic\n  Smoothing",
    "authors": [
      "Jiabao Ji",
      "Bairu Hou",
      "Alexander Robey",
      "George J. Pappas",
      "Hamed Hassani",
      "Yang Zhang",
      "Eric Wong",
      "Shiyu Chang"
    ],
    "date": "2024-02-25T20:36:03Z",
    "url": "http://arxiv.org/abs/2402.16192v2",
    "source": "arxiv"
  },
  {
    "title": "DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM\n  Jailbreakers",
    "authors": [
      "Xirui Li",
      "Ruochen Wang",
      "Minhao Cheng",
      "Tianyi Zhou",
      "Cho-Jui Hsieh"
    ],
    "date": "2024-02-25T17:43:29Z",
    "url": "http://arxiv.org/abs/2402.16914v3",
    "source": "arxiv"
  },
  {
    "title": "Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts\n  Against Open-source LLMs",
    "authors": [
      "Xiaoxia Li",
      "Siyuan Liang",
      "Jiyi Zhang",
      "Han Fang",
      "Aishan Liu",
      "Ee-Chien Chang"
    ],
    "date": "2024-02-21T15:13:50Z",
    "url": "http://arxiv.org/abs/2402.14872v2",
    "source": "arxiv"
  },
  {
    "title": "When \"Competency\" in Reasoning Opens the Door to Vulnerability:\n  Jailbreaking LLMs via Novel Complex Ciphers",
    "authors": [
      "Divij Handa",
      "Zehua Zhang",
      "Amir Saeidi",
      "Shrinidhi Kumbhar",
      "Md Nayem Uddin",
      "Aswin RRV",
      "Chitta Baral"
    ],
    "date": "2024-02-16T11:37:05Z",
    "url": "http://arxiv.org/abs/2402.10601v5",
    "source": "arxiv"
  },
  {
    "title": "Leveraging the Context through Multi-Round Interactions for Jailbreaking\n  Attacks",
    "authors": [
      "Yixin Cheng",
      "Markos Georgopoulos",
      "Volkan Cevher",
      "Grigorios G. Chrysos"
    ],
    "date": "2024-02-14T13:45:19Z",
    "url": "http://arxiv.org/abs/2402.09177v2",
    "source": "arxiv"
  },
  {
    "title": "JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against\n  LLMs",
    "authors": [
      "Junjie Chu",
      "Yugeng Liu",
      "Ziqing Yang",
      "Xinyue Shen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "date": "2024-02-08T13:42:50Z",
    "url": "http://arxiv.org/abs/2402.05668v3",
    "source": "arxiv"
  },
  {
    "title": "Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank\n  Modifications",
    "authors": [
      "Boyi Wei",
      "Kaixuan Huang",
      "Yangsibo Huang",
      "Tinghao Xie",
      "Xiangyu Qi",
      "Mengzhou Xia",
      "Prateek Mittal",
      "Mengdi Wang",
      "Peter Henderson"
    ],
    "date": "2024-02-07T18:34:38Z",
    "url": "http://arxiv.org/abs/2402.05162v4",
    "source": "arxiv"
  },
  {
    "title": "SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large\n  Language Models",
    "authors": [
      "Lijun Li",
      "Bowen Dong",
      "Ruohui Wang",
      "Xuhao Hu",
      "Wangmeng Zuo",
      "Dahua Lin",
      "Yu Qiao",
      "Jing Shao"
    ],
    "date": "2024-02-07T17:33:54Z",
    "url": "http://arxiv.org/abs/2402.05044v4",
    "source": "arxiv"
  },
  {
    "title": "HarmBench: A Standardized Evaluation Framework for Automated Red Teaming\n  and Robust Refusal",
    "authors": [
      "Mantas Mazeika",
      "Long Phan",
      "Xuwang Yin",
      "Andy Zou",
      "Zifan Wang",
      "Norman Mu",
      "Elham Sakhaee",
      "Nathaniel Li",
      "Steven Basart",
      "Bo Li",
      "David Forsyth",
      "Dan Hendrycks"
    ],
    "date": "2024-02-06T18:59:08Z",
    "url": "http://arxiv.org/abs/2402.04249v2",
    "source": "arxiv"
  },
  {
    "title": "Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large\n  Language Models",
    "authors": [
      "Yongshuo Zong",
      "Ondrej Bohdal",
      "Tingyang Yu",
      "Yongxin Yang",
      "Timothy Hospedales"
    ],
    "date": "2024-02-03T16:43:42Z",
    "url": "http://arxiv.org/abs/2402.02207v2",
    "source": "arxiv"
  },
  {
    "title": "Weak-to-Strong Jailbreaking on Large Language Models",
    "authors": [
      "Xuandong Zhao",
      "Xianjun Yang",
      "Tianyu Pang",
      "Chao Du",
      "Lei Li",
      "Yu-Xiang Wang",
      "William Yang Wang"
    ],
    "date": "2024-01-30T18:48:37Z",
    "url": "http://arxiv.org/abs/2401.17256v5",
    "source": "arxiv"
  },
  {
    "title": "The Language Barrier: Dissecting Safety Challenges of LLMs in\n  Multilingual Contexts",
    "authors": [
      "Lingfeng Shen",
      "Weiting Tan",
      "Sihao Chen",
      "Yunmo Chen",
      "Jingyu Zhang",
      "Haoran Xu",
      "Boyuan Zheng",
      "Philipp Koehn",
      "Daniel Khashabi"
    ],
    "date": "2024-01-23T23:12:09Z",
    "url": "http://arxiv.org/abs/2401.13136v1",
    "source": "arxiv"
  },
  {
    "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents",
    "authors": [
      "Tongxin Yuan",
      "Zhiwei He",
      "Lingzhong Dong",
      "Yiming Wang",
      "Ruijie Zhao",
      "Tian Xia",
      "Lizhen Xu",
      "Binglin Zhou",
      "Fangqi Li",
      "Zhuosheng Zhang",
      "Rui Wang",
      "Gongshen Liu"
    ],
    "date": "2024-01-18T14:40:46Z",
    "url": "http://arxiv.org/abs/2401.10019v3",
    "source": "arxiv"
  },
  {
    "title": "How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to\n  Challenge AI Safety by Humanizing LLMs",
    "authors": [
      "Yi Zeng",
      "Hongpeng Lin",
      "Jingwen Zhang",
      "Diyi Yang",
      "Ruoxi Jia",
      "Weiyan Shi"
    ],
    "date": "2024-01-12T16:13:24Z",
    "url": "http://arxiv.org/abs/2401.06373v2",
    "source": "arxiv"
  },
  {
    "title": "Revisiting Jailbreaking for Large Language Models: A Representation\n  Engineering Perspective",
    "authors": [
      "Tianlong Li",
      "Zhenghua Wang",
      "Wenhao Liu",
      "Muling Wu",
      "Shihan Dou",
      "Changze Lv",
      "Xiaohua Wang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "date": "2024-01-12T00:50:04Z",
    "url": "http://arxiv.org/abs/2401.06824v5",
    "source": "arxiv"
  },
  {
    "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
    "authors": [
      "Yunfan Gao",
      "Yun Xiong",
      "Xinyu Gao",
      "Kangxiang Jia",
      "Jinliu Pan",
      "Yuxi Bi",
      "Yi Dai",
      "Jiawei Sun",
      "Meng Wang",
      "Haofen Wang"
    ],
    "date": "2023-12-18T07:47:33Z",
    "url": "http://arxiv.org/abs/2312.10997v5",
    "source": "arxiv"
  },
  {
    "title": "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations",
    "authors": [
      "Hakan Inan",
      "Kartikeya Upasani",
      "Jianfeng Chi",
      "Rashi Rungta",
      "Krithika Iyer",
      "Yuning Mao",
      "Michael Tontchev",
      "Qing Hu",
      "Brian Fuller",
      "Davide Testuggine",
      "Madian Khabsa"
    ],
    "date": "2023-12-07T19:40:50Z",
    "url": "http://arxiv.org/abs/2312.06674v1",
    "source": "arxiv"
  },
  {
    "title": "Tree of Attacks: Jailbreaking Black-Box LLMs Automatically",
    "authors": [
      "Anay Mehrotra",
      "Manolis Zampetakis",
      "Paul Kassianik",
      "Blaine Nelson",
      "Hyrum Anderson",
      "Yaron Singer",
      "Amin Karbasi"
    ],
    "date": "2023-12-04T18:49:23Z",
    "url": "http://arxiv.org/abs/2312.02119v3",
    "source": "arxiv"
  },
  {
    "title": "Taiwan LLM: Bridging the Linguistic Divide with a Culturally Aligned\n  Language Model",
    "authors": [
      "Yen-Ting Lin",
      "Yun-Nung Chen"
    ],
    "date": "2023-11-29T09:48:34Z",
    "url": "http://arxiv.org/abs/2311.17487v1",
    "source": "arxiv"
  },
  {
    "title": "Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information",
    "authors": [
      "Zhengmian Hu",
      "Gang Wu",
      "Saayan Mitra",
      "Ruiyi Zhang",
      "Tong Sun",
      "Heng Huang",
      "Viswanathan Swaminathan"
    ],
    "date": "2023-11-20T03:17:21Z",
    "url": "http://arxiv.org/abs/2311.11509v3",
    "source": "arxiv"
  },
  {
    "title": "Cognitive Overload: Jailbreaking Large Language Models with Overloaded\n  Logical Thinking",
    "authors": [
      "Nan Xu",
      "Fei Wang",
      "Ben Zhou",
      "Bang Zheng Li",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "date": "2023-11-16T11:52:22Z",
    "url": "http://arxiv.org/abs/2311.09827v2",
    "source": "arxiv"
  },
  {
    "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
    "authors": [
      "Garima Agrawal",
      "Tharindu Kumarage",
      "Zeyad Alghamdi",
      "Huan Liu"
    ],
    "date": "2023-11-14T05:21:57Z",
    "url": "http://arxiv.org/abs/2311.07914v2",
    "source": "arxiv"
  },
  {
    "title": "MART: Improving LLM Safety with Multi-round Automatic Red-Teaming",
    "authors": [
      "Suyu Ge",
      "Chunting Zhou",
      "Rui Hou",
      "Madian Khabsa",
      "Yi-Chia Wang",
      "Qifan Wang",
      "Jiawei Han",
      "Yuning Mao"
    ],
    "date": "2023-11-13T19:13:29Z",
    "url": "http://arxiv.org/abs/2311.07689v1",
    "source": "arxiv"
  },
  {
    "title": "A Survey on Hallucination in Large Language Models: Principles,\n  Taxonomy, Challenges, and Open Questions",
    "authors": [
      "Lei Huang",
      "Weijiang Yu",
      "Weitao Ma",
      "Weihong Zhong",
      "Zhangyin Feng",
      "Haotian Wang",
      "Qianglong Chen",
      "Weihua Peng",
      "Xiaocheng Feng",
      "Bing Qin",
      "Ting Liu"
    ],
    "date": "2023-11-09T09:25:37Z",
    "url": "http://arxiv.org/abs/2311.05232v2",
    "source": "arxiv"
  },
  {
    "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation",
    "authors": [
      "Rusheb Shah",
      "Quentin Feuillade--Montixi",
      "Soroush Pour",
      "Arush Tagade",
      "Stephen Casper",
      "Javier Rando"
    ],
    "date": "2023-11-06T18:55:18Z",
    "url": "http://arxiv.org/abs/2311.03348v2",
    "source": "arxiv"
  },
  {
    "title": "Robust Safety Classifier for Large Language Models: Adversarial Prompt\n  Shield",
    "authors": [
      "Jinhwa Kim",
      "Ali Derakhshan",
      "Ian G. Harris"
    ],
    "date": "2023-10-31T22:22:10Z",
    "url": "http://arxiv.org/abs/2311.00172v1",
    "source": "arxiv"
  },
  {
    "title": "Improving Few-shot Generalization of Safety Classifiers via Data\n  Augmented Parameter-Efficient Fine-Tuning",
    "authors": [
      "Ananth Balashankar",
      "Xiao Ma",
      "Aradhana Sinha",
      "Ahmad Beirami",
      "Yao Qin",
      "Jilin Chen",
      "Alex Beutel"
    ],
    "date": "2023-10-25T19:57:07Z",
    "url": "http://arxiv.org/abs/2310.16959v1",
    "source": "arxiv"
  },
  {
    "title": "AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large\n  Language Models",
    "authors": [
      "Sicheng Zhu",
      "Ruiyi Zhang",
      "Bang An",
      "Gang Wu",
      "Joe Barrow",
      "Zichao Wang",
      "Furong Huang",
      "Ani Nenkova",
      "Tong Sun"
    ],
    "date": "2023-10-23T17:46:07Z",
    "url": "http://arxiv.org/abs/2310.15140v2",
    "source": "arxiv"
  },
  {
    "title": "Jailbreaking Black Box Large Language Models in Twenty Queries",
    "authors": [
      "Patrick Chao",
      "Alexander Robey",
      "Edgar Dobriban",
      "Hamed Hassani",
      "George J. Pappas",
      "Eric Wong"
    ],
    "date": "2023-10-12T15:38:28Z",
    "url": "http://arxiv.org/abs/2310.08419v4",
    "source": "arxiv"
  },
  {
    "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation",
    "authors": [
      "Yangsibo Huang",
      "Samyak Gupta",
      "Mengzhou Xia",
      "Kai Li",
      "Danqi Chen"
    ],
    "date": "2023-10-10T20:15:54Z",
    "url": "http://arxiv.org/abs/2310.06987v1",
    "source": "arxiv"
  },
  {
    "title": "Multilingual Jailbreak Challenges in Large Language Models",
    "authors": [
      "Yue Deng",
      "Wenxuan Zhang",
      "Sinno Jialin Pan",
      "Lidong Bing"
    ],
    "date": "2023-10-10T09:44:06Z",
    "url": "http://arxiv.org/abs/2310.06474v3",
    "source": "arxiv"
  },
  {
    "title": "Jailbreak and Guard Aligned Language Models with Only Few In-Context\n  Demonstrations",
    "authors": [
      "Zeming Wei",
      "Yifei Wang",
      "Ang Li",
      "Yichuan Mo",
      "Yisen Wang"
    ],
    "date": "2023-10-10T07:50:29Z",
    "url": "http://arxiv.org/abs/2310.06387v3",
    "source": "arxiv"
  },
  {
    "title": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety\n  Benchmark for Large Language Models in Chinese",
    "authors": [
      "Liang Xu",
      "Kangkang Zhao",
      "Lei Zhu",
      "Hang Xue"
    ],
    "date": "2023-10-09T16:03:22Z",
    "url": "http://arxiv.org/abs/2310.05818v1",
    "source": "arxiv"
  },
  {
    "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users\n  Do Not Intend To!",
    "authors": [
      "Xiangyu Qi",
      "Yi Zeng",
      "Tinghao Xie",
      "Pin-Yu Chen",
      "Ruoxi Jia",
      "Prateek Mittal",
      "Peter Henderson"
    ],
    "date": "2023-10-05T17:12:17Z",
    "url": "http://arxiv.org/abs/2310.03693v1",
    "source": "arxiv"
  },
  {
    "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks",
    "authors": [
      "Alexander Robey",
      "Eric Wong",
      "Hamed Hassani",
      "George J. Pappas"
    ],
    "date": "2023-10-05T17:01:53Z",
    "url": "http://arxiv.org/abs/2310.03684v4",
    "source": "arxiv"
  },
  {
    "title": "Low-Resource Languages Jailbreak GPT-4",
    "authors": [
      "Zheng-Xin Yong",
      "Cristina Menghini",
      "Stephen H. Bach"
    ],
    "date": "2023-10-03T21:30:56Z",
    "url": "http://arxiv.org/abs/2310.02446v2",
    "source": "arxiv"
  },
  {
    "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language\n  Models",
    "authors": [
      "Xiaogeng Liu",
      "Nan Xu",
      "Muhao Chen",
      "Chaowei Xiao"
    ],
    "date": "2023-10-03T19:44:37Z",
    "url": "http://arxiv.org/abs/2310.04451v2",
    "source": "arxiv"
  },
  {
    "title": "On the Safety of Open-Sourced Large Language Models: Does Alignment\n  Really Prevent Them From Being Misused?",
    "authors": [
      "Hangfan Zhang",
      "Zhimeng Guo",
      "Huaisheng Zhu",
      "Bochuan Cao",
      "Lu Lin",
      "Jinyuan Jia",
      "Jinghui Chen",
      "Dinghao Wu"
    ],
    "date": "2023-10-02T19:22:01Z",
    "url": "http://arxiv.org/abs/2310.01581v1",
    "source": "arxiv"
  },
  {
    "title": "All Languages Matter: On the Multilingual Safety of Large Language\n  Models",
    "authors": [
      "Wenxuan Wang",
      "Zhaopeng Tu",
      "Chang Chen",
      "Youliang Yuan",
      "Jen-tse Huang",
      "Wenxiang Jiao",
      "Michael R. Lyu"
    ],
    "date": "2023-10-02T05:23:34Z",
    "url": "http://arxiv.org/abs/2310.00905v2",
    "source": "arxiv"
  },
  {
    "title": "GPTFUZZER: Red Teaming Large Language Models with Auto-Generated\n  Jailbreak Prompts",
    "authors": [
      "Jiahao Yu",
      "Xingwei Lin",
      "Zheng Yu",
      "Xinyu Xing"
    ],
    "date": "2023-09-19T02:19:48Z",
    "url": "http://arxiv.org/abs/2309.10253v4",
    "source": "arxiv"
  },
  {
    "title": "Advancing the Evaluation of Traditional Chinese Language Models: Towards\n  a Comprehensive Benchmark Suite",
    "authors": [
      "Chan-Jan Hsu",
      "Chang-Le Liu",
      "Feng-Ting Liao",
      "Po-Chun Hsu",
      "Yi-Chang Chen",
      "Da-shan Shiu"
    ],
    "date": "2023-09-15T14:52:23Z",
    "url": "http://arxiv.org/abs/2309.08448v2",
    "source": "arxiv"
  },
  {
    "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\n  Models",
    "authors": [
      "Neel Jain",
      "Avi Schwarzschild",
      "Yuxin Wen",
      "Gowthami Somepalli",
      "John Kirchenbauer",
      "Ping-yeh Chiang",
      "Micah Goldblum",
      "Aniruddha Saha",
      "Jonas Geiping",
      "Tom Goldstein"
    ],
    "date": "2023-09-01T17:59:44Z",
    "url": "http://arxiv.org/abs/2309.00614v2",
    "source": "arxiv"
  },
  {
    "title": "Detecting Language Model Attacks with Perplexity",
    "authors": [
      "Gabriel Alon",
      "Michael Kamfonas"
    ],
    "date": "2023-08-27T15:20:06Z",
    "url": "http://arxiv.org/abs/2308.14132v3",
    "source": "arxiv"
  },
  {
    "title": "Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs",
    "authors": [
      "Yuxia Wang",
      "Haonan Li",
      "Xudong Han",
      "Preslav Nakov",
      "Timothy Baldwin"
    ],
    "date": "2023-08-25T14:02:12Z",
    "url": "http://arxiv.org/abs/2308.13387v2",
    "source": "arxiv"
  },
  {
    "title": "GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher",
    "authors": [
      "Youliang Yuan",
      "Wenxiang Jiao",
      "Wenxuan Wang",
      "Jen-tse Huang",
      "Pinjia He",
      "Shuming Shi",
      "Zhaopeng Tu"
    ],
    "date": "2023-08-12T04:05:57Z",
    "url": "http://arxiv.org/abs/2308.06463v2",
    "source": "arxiv"
  },
  {
    "title": "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak\n  Prompts on Large Language Models",
    "authors": [
      "Xinyue Shen",
      "Zeyuan Chen",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "date": "2023-08-07T16:55:20Z",
    "url": "http://arxiv.org/abs/2308.03825v2",
    "source": "arxiv"
  },
  {
    "title": "Universal and Transferable Adversarial Attacks on Aligned Language\n  Models",
    "authors": [
      "Andy Zou",
      "Zifan Wang",
      "Nicholas Carlini",
      "Milad Nasr",
      "J. Zico Kolter",
      "Matt Fredrikson"
    ],
    "date": "2023-07-27T17:49:12Z",
    "url": "http://arxiv.org/abs/2307.15043v2",
    "source": "arxiv"
  },
  {
    "title": "CValues: Measuring the Values of Chinese Large Language Models from\n  Safety to Responsibility",
    "authors": [
      "Guohai Xu",
      "Jiayi Liu",
      "Ming Yan",
      "Haotian Xu",
      "Jinghui Si",
      "Zhuoran Zhou",
      "Peng Yi",
      "Xing Gao",
      "Jitao Sang",
      "Rong Zhang",
      "Ji Zhang",
      "Chao Peng",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "date": "2023-07-19T01:22:40Z",
    "url": "http://arxiv.org/abs/2307.09705v1",
    "source": "arxiv"
  },
  {
    "title": "MasterKey: Automated Jailbreak Across Multiple Large Language Model\n  Chatbots",
    "authors": [
      "Gelei Deng",
      "Yi Liu",
      "Yuekang Li",
      "Kailong Wang",
      "Ying Zhang",
      "Zefeng Li",
      "Haoyu Wang",
      "Tianwei Zhang",
      "Yang Liu"
    ],
    "date": "2023-07-16T01:07:15Z",
    "url": "http://arxiv.org/abs/2307.08715v2",
    "source": "arxiv"
  },
  {
    "title": "Jailbroken: How Does LLM Safety Training Fail?",
    "authors": [
      "Alexander Wei",
      "Nika Haghtalab",
      "Jacob Steinhardt"
    ],
    "date": "2023-07-05T17:58:10Z",
    "url": "http://arxiv.org/abs/2307.02483v1",
    "source": "arxiv"
  },
  {
    "title": "Are aligned neural networks adversarially aligned?",
    "authors": [
      "Nicholas Carlini",
      "Milad Nasr",
      "Christopher A. Choquette-Choo",
      "Matthew Jagielski",
      "Irena Gao",
      "Anas Awadalla",
      "Pang Wei Koh",
      "Daphne Ippolito",
      "Katherine Lee",
      "Florian Tramer",
      "Ludwig Schmidt"
    ],
    "date": "2023-06-26T17:18:44Z",
    "url": "http://arxiv.org/abs/2306.15447v2",
    "source": "arxiv"
  },
  {
    "title": "Prompt Injection attack against LLM-integrated Applications",
    "authors": [
      "Yi Liu",
      "Gelei Deng",
      "Yuekang Li",
      "Kailong Wang",
      "Zihao Wang",
      "Xiaofeng Wang",
      "Tianwei Zhang",
      "Yepang Liu",
      "Haoyu Wang",
      "Yan Zheng",
      "Yang Liu"
    ],
    "date": "2023-06-08T18:43:11Z",
    "url": "http://arxiv.org/abs/2306.05499v2",
    "source": "arxiv"
  },
  {
    "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language\n  Model",
    "authors": [
      "Kenneth Li",
      "Oam Patel",
      "Fernanda Viégas",
      "Hanspeter Pfister",
      "Martin Wattenberg"
    ],
    "date": "2023-06-06T01:26:53Z",
    "url": "http://arxiv.org/abs/2306.03341v6",
    "source": "arxiv"
  },
  {
    "title": "Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study",
    "authors": [
      "Yi Liu",
      "Gelei Deng",
      "Zhengzi Xu",
      "Yuekang Li",
      "Yaowen Zheng",
      "Ying Zhang",
      "Lida Zhao",
      "Tianwei Zhang",
      "Kailong Wang",
      "Yang Liu"
    ],
    "date": "2023-05-23T09:33:38Z",
    "url": "http://arxiv.org/abs/2305.13860v2",
    "source": "arxiv"
  },
  {
    "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models",
    "authors": [
      "Ameet Deshpande",
      "Vishvak Murahari",
      "Tanmay Rajpurohit",
      "Ashwin Kalyan",
      "Karthik Narasimhan"
    ],
    "date": "2023-04-11T16:53:54Z",
    "url": "http://arxiv.org/abs/2304.05335v1",
    "source": "arxiv"
  },
  {
    "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
    "authors": [
      "Haoran Li",
      "Dadi Guo",
      "Wei Fan",
      "Mingshi Xu",
      "Jie Huang",
      "Fanpu Meng",
      "Yangqiu Song"
    ],
    "date": "2023-04-11T13:05:04Z",
    "url": "http://arxiv.org/abs/2304.05197v3",
    "source": "arxiv"
  },
  {
    "title": "Automatically Auditing Large Language Models via Discrete Optimization",
    "authors": [
      "Erik Jones",
      "Anca Dragan",
      "Aditi Raghunathan",
      "Jacob Steinhardt"
    ],
    "date": "2023-03-08T05:09:59Z",
    "url": "http://arxiv.org/abs/2303.04381v1",
    "source": "arxiv"
  },
  {
    "title": "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation\n  in Natural Language Generation",
    "authors": [
      "Lorenz Kuhn",
      "Yarin Gal",
      "Sebastian Farquhar"
    ],
    "date": "2023-02-19T20:10:07Z",
    "url": "http://arxiv.org/abs/2302.09664v3",
    "source": "arxiv"
  },
  {
    "title": "Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard\n  Security Attacks",
    "authors": [
      "Daniel Kang",
      "Xuechen Li",
      "Ion Stoica",
      "Carlos Guestrin",
      "Matei Zaharia",
      "Tatsunori Hashimoto"
    ],
    "date": "2023-02-11T15:57:44Z",
    "url": "http://arxiv.org/abs/2302.05733v1",
    "source": "arxiv"
  },
  {
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "authors": [
      "Yuntao Bai",
      "Saurav Kadavath",
      "Sandipan Kundu",
      "Amanda Askell",
      "Jackson Kernion",
      "Andy Jones",
      "Anna Chen",
      "Anna Goldie",
      "Azalia Mirhoseini",
      "Cameron McKinnon",
      "Carol Chen",
      "Catherine Olsson",
      "Christopher Olah",
      "Danny Hernandez",
      "Dawn Drain",
      "Deep Ganguli",
      "Dustin Li",
      "Eli Tran-Johnson",
      "Ethan Perez",
      "Jamie Kerr",
      "Jared Mueller",
      "Jeffrey Ladish",
      "Joshua Landau",
      "Kamal Ndousse",
      "Kamile Lukosuite",
      "Liane Lovitt",
      "Michael Sellitto",
      "Nelson Elhage",
      "Nicholas Schiefer",
      "Noemi Mercado",
      "Nova DasSarma",
      "Robert Lasenby",
      "Robin Larson",
      "Sam Ringer",
      "Scott Johnston",
      "Shauna Kravec",
      "Sheer El Showk",
      "Stanislav Fort",
      "Tamera Lanham",
      "Timothy Telleen-Lawton",
      "Tom Conerly",
      "Tom Henighan",
      "Tristan Hume",
      "Samuel R. Bowman",
      "Zac Hatfield-Dodds",
      "Ben Mann",
      "Dario Amodei",
      "Nicholas Joseph",
      "Sam McCandlish",
      "Tom Brown",
      "Jared Kaplan"
    ],
    "date": "2022-12-15T06:19:23Z",
    "url": "http://arxiv.org/abs/2212.08073v1",
    "source": "arxiv"
  },
  {
    "title": "Ignore Previous Prompt: Attack Techniques For Language Models",
    "authors": [
      "Fábio Perez",
      "Ian Ribeiro"
    ],
    "date": "2022-11-17T13:43:20Z",
    "url": "http://arxiv.org/abs/2211.09527v1",
    "source": "arxiv"
  },
  {
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "authors": [
      "Shunyu Yao",
      "Jeffrey Zhao",
      "Dian Yu",
      "Nan Du",
      "Izhak Shafran",
      "Karthik Narasimhan",
      "Yuan Cao"
    ],
    "date": "2022-10-06T01:00:32Z",
    "url": "http://arxiv.org/abs/2210.03629v3",
    "source": "arxiv"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "authors": [
      "Todor Markov",
      "Chong Zhang",
      "Sandhini Agarwal",
      "Tyna Eloundou",
      "Teddy Lee",
      "Steven Adler",
      "Angela Jiang",
      "Lilian Weng"
    ],
    "date": "2022-08-05T16:47:23Z",
    "url": "http://arxiv.org/abs/2208.03274v2",
    "source": "arxiv"
  },
  {
    "title": "Emergent Abilities of Large Language Models",
    "authors": [
      "Jason Wei",
      "Yi Tay",
      "Rishi Bommasani",
      "Colin Raffel",
      "Barret Zoph",
      "Sebastian Borgeaud",
      "Dani Yogatama",
      "Maarten Bosma",
      "Denny Zhou",
      "Donald Metzler",
      "Ed H. Chi",
      "Tatsunori Hashimoto",
      "Oriol Vinyals",
      "Percy Liang",
      "Jeff Dean",
      "William Fedus"
    ],
    "date": "2022-06-15T17:32:01Z",
    "url": "http://arxiv.org/abs/2206.07682v2",
    "source": "arxiv"
  },
  {
    "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning\n  from Human Feedback",
    "authors": [
      "Yuntao Bai",
      "Andy Jones",
      "Kamal Ndousse",
      "Amanda Askell",
      "Anna Chen",
      "Nova DasSarma",
      "Dawn Drain",
      "Stanislav Fort",
      "Deep Ganguli",
      "Tom Henighan",
      "Nicholas Joseph",
      "Saurav Kadavath",
      "Jackson Kernion",
      "Tom Conerly",
      "Sheer El-Showk",
      "Nelson Elhage",
      "Zac Hatfield-Dodds",
      "Danny Hernandez",
      "Tristan Hume",
      "Scott Johnston",
      "Shauna Kravec",
      "Liane Lovitt",
      "Neel Nanda",
      "Catherine Olsson",
      "Dario Amodei",
      "Tom Brown",
      "Jack Clark",
      "Sam McCandlish",
      "Chris Olah",
      "Ben Mann",
      "Jared Kaplan"
    ],
    "date": "2022-04-12T15:02:38Z",
    "url": "http://arxiv.org/abs/2204.05862v1",
    "source": "arxiv"
  },
  {
    "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
    "authors": [
      "Xuezhi Wang",
      "Jason Wei",
      "Dale Schuurmans",
      "Quoc Le",
      "Ed Chi",
      "Sharan Narang",
      "Aakanksha Chowdhery",
      "Denny Zhou"
    ],
    "date": "2022-03-21T17:48:52Z",
    "url": "http://arxiv.org/abs/2203.11171v4",
    "source": "arxiv"
  },
  {
    "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and\n  Implicit Hate Speech Detection",
    "authors": [
      "Thomas Hartvigsen",
      "Saadia Gabriel",
      "Hamid Palangi",
      "Maarten Sap",
      "Dipankar Ray",
      "Ece Kamar"
    ],
    "date": "2022-03-17T17:57:56Z",
    "url": "http://arxiv.org/abs/2203.09509v4",
    "source": "arxiv"
  },
  {
    "title": "A New Generation of Perspective API: Efficient Multilingual\n  Character-level Transformers",
    "authors": [
      "Alyssa Lees",
      "Vinh Q. Tran",
      "Yi Tay",
      "Jeffrey Sorensen",
      "Jai Gupta",
      "Donald Metzler",
      "Lucy Vasserman"
    ],
    "date": "2022-02-22T20:55:31Z",
    "url": "http://arxiv.org/abs/2202.11176v1",
    "source": "arxiv"
  },
  {
    "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Brian Ichter",
      "Fei Xia",
      "Ed Chi",
      "Quoc Le",
      "Denny Zhou"
    ],
    "date": "2022-01-28T02:33:07Z",
    "url": "http://arxiv.org/abs/2201.11903v6",
    "source": "arxiv"
  },
  {
    "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
    "authors": [
      "Stephanie Lin",
      "Jacob Hilton",
      "Owain Evans"
    ],
    "date": "2021-09-08T17:15:27Z",
    "url": "http://arxiv.org/abs/2109.07958v2",
    "source": "arxiv"
  },
  {
    "title": "Recipes for Safety in Open-domain Chatbots",
    "authors": [
      "Jing Xu",
      "Da Ju",
      "Margaret Li",
      "Y-Lan Boureau",
      "Jason Weston",
      "Emily Dinan"
    ],
    "date": "2020-10-14T13:26:39Z",
    "url": "http://arxiv.org/abs/2010.07079v3",
    "source": "arxiv"
  },
  {
    "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language\n  Models",
    "authors": [
      "Samuel Gehman",
      "Suchin Gururangan",
      "Maarten Sap",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "date": "2020-09-24T03:17:19Z",
    "url": "http://arxiv.org/abs/2009.11462v2",
    "source": "arxiv"
  },
  {
    "title": "Language Models are Few-Shot Learners",
    "authors": [
      "Tom B. Brown",
      "Benjamin Mann",
      "Nick Ryder",
      "Melanie Subbiah",
      "Jared Kaplan",
      "Prafulla Dhariwal",
      "Arvind Neelakantan",
      "Pranav Shyam",
      "Girish Sastry",
      "Amanda Askell",
      "Sandhini Agarwal",
      "Ariel Herbert-Voss",
      "Gretchen Krueger",
      "Tom Henighan",
      "Rewon Child",
      "Aditya Ramesh",
      "Daniel M. Ziegler",
      "Jeffrey Wu",
      "Clemens Winter",
      "Christopher Hesse",
      "Mark Chen",
      "Eric Sigler",
      "Mateusz Litwin",
      "Scott Gray",
      "Benjamin Chess",
      "Jack Clark",
      "Christopher Berner",
      "Sam McCandlish",
      "Alec Radford",
      "Ilya Sutskever",
      "Dario Amodei"
    ],
    "date": "2020-05-28T17:29:03Z",
    "url": "http://arxiv.org/abs/2005.14165v4",
    "source": "arxiv"
  },
  {
    "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
    "authors": [
      "Patrick Lewis",
      "Ethan Perez",
      "Aleksandra Piktus",
      "Fabio Petroni",
      "Vladimir Karpukhin",
      "Naman Goyal",
      "Heinrich Küttler",
      "Mike Lewis",
      "Wen-tau Yih",
      "Tim Rocktäschel",
      "Sebastian Riedel",
      "Douwe Kiela"
    ],
    "date": "2020-05-22T21:34:34Z",
    "url": "http://arxiv.org/abs/2005.11401v4",
    "source": "arxiv"
  },
  {
    "title": "Deep Double Descent: Where Bigger Models and More Data Hurt",
    "authors": [
      "Preetum Nakkiran",
      "Gal Kaplun",
      "Yamini Bansal",
      "Tristan Yang",
      "Boaz Barak",
      "Ilya Sutskever"
    ],
    "date": "2019-12-04T22:47:31Z",
    "url": "http://arxiv.org/abs/1912.02292v1",
    "source": "arxiv"
  },
  {
    "title": "Attention Is All You Need",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "Lukasz Kaiser",
      "Illia Polosukhin"
    ],
    "date": "2017-06-12T17:57:34Z",
    "url": "http://arxiv.org/abs/1706.03762v7",
    "source": "arxiv"
  },
  {
    "title": "Understanding deep learning requires rethinking generalization",
    "authors": [
      "Chiyuan Zhang",
      "Samy Bengio",
      "Moritz Hardt",
      "Benjamin Recht",
      "Oriol Vinyals"
    ],
    "date": "2016-11-10T22:02:36Z",
    "url": "http://arxiv.org/abs/1611.03530v2",
    "source": "arxiv"
  },
  {
    "title": "XGBoost: A Scalable Tree Boosting System",
    "authors": [
      "Tianqi Chen",
      "Carlos Guestrin"
    ],
    "date": "2016-03-09T01:11:51Z",
    "url": "http://arxiv.org/abs/1603.02754v3",
    "source": "arxiv"
  },
  {
    "title": "Deep Residual Learning for Image Recognition",
    "authors": [
      "Kaiming He",
      "Xiangyu Zhang",
      "Shaoqing Ren",
      "Jian Sun"
    ],
    "date": "2015-12-10T19:51:55Z",
    "url": "http://arxiv.org/abs/1512.03385v1",
    "source": "arxiv"
  },
  {
    "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
    "authors": [
      "Olaf Ronneberger",
      "Philipp Fischer",
      "Thomas Brox"
    ],
    "date": "2015-05-18T11:28:37Z",
    "url": "http://arxiv.org/abs/1505.04597v1",
    "source": "arxiv"
  }
]